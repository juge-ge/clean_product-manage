# æ¸…æ´ç”Ÿäº§æ™ºæ…§å®¡æ ¸å¹³å°è¿ç»´æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºæ¸…æ´ç”Ÿäº§æ™ºæ…§å®¡æ ¸å¹³å°çš„è¿ç»´æ“ä½œæŒ‡å—ï¼Œæ¶µç›–ç³»ç»Ÿç›‘æ§ã€æ—¥å¿—ç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–ã€ç‰ˆæœ¬å‡çº§ç­‰æ ¸å¿ƒè¿ç»´å·¥ä½œã€‚å¹³å°åŸºäº FastAPI + Tortoise ORM + SQLite æ„å»ºï¼Œæ”¯æŒå¤šè¡Œä¸šæ¸…æ´ç”Ÿäº§å®¡æ ¸ç®¡ç†ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æŠ€æœ¯æ ˆ
- **åç«¯æ¡†æ¶**: FastAPI 0.111.0
- **æ•°æ®åº“ORM**: Tortoise ORM 0.23.0
- **æ•°æ®åº“**: SQLite (æ”¯æŒ MySQL/PostgreSQL)
- **è®¤è¯æˆæƒ**: JWT + RBAC
- **æ—¥å¿—ç³»ç»Ÿ**: Uvicorn + Loguru
- **è¿›ç¨‹ç®¡ç†**: Uvicorn ASGI Server

### ç›®å½•ç»“æ„
```
vue-fastapi-admin-main/
â”œâ”€â”€ app/                    # åº”ç”¨æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ api/               # APIè·¯ç”±
â”‚   â”œâ”€â”€ controllers/       # ä¸šåŠ¡æ§åˆ¶å™¨
â”‚   â”œâ”€â”€ models/           # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ schemas/          # æ•°æ®éªŒè¯
â”‚   â”œâ”€â”€ core/             # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ settings/         # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ log/              # æ—¥å¿—æ¨¡å—
â”œâ”€â”€ web/                   # å‰ç«¯ä»£ç 
â”œâ”€â”€ db.sqlite3            # SQLiteæ•°æ®åº“
â”œâ”€â”€ run.py                # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ requirements.txt      # Pythonä¾èµ–
â””â”€â”€ migrations/           # æ•°æ®åº“è¿ç§»
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚
- **Python**: 3.11+
- **å†…å­˜**: æœ€å°2GBï¼Œæ¨è4GB+
- **å­˜å‚¨**: æœ€å°10GBï¼Œæ¨è50GB+
- **ç½‘ç»œ**: æ”¯æŒHTTP/HTTPSè®¿é—®

### ä¾èµ–å®‰è£…
```bash
# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python -c "import fastapi, tortoise; print('Dependencies installed successfully')"
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# æ•°æ®åº“é…ç½®
export DATABASE_URL="sqlite:///db.sqlite3"

# JWTé…ç½®
export SECRET_KEY="your-secret-key-here"
export JWT_ACCESS_TOKEN_EXPIRE_MINUTES=10080

# æ—¥å¿—é…ç½®
export LOG_LEVEL="INFO"
export LOG_FILE_PATH="/var/log/clean-production-platform.log"
```

## ğŸš€ éƒ¨ç½²ä¸å¯åŠ¨

### å¼€å‘ç¯å¢ƒå¯åŠ¨
```bash
# ç›´æ¥å¯åŠ¨ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
python run.py

# ä½¿ç”¨uvicornå¯åŠ¨
uvicorn app:app --host 0.0.0.0 --port 9999 --reload
```

### ç”Ÿäº§ç¯å¢ƒå¯åŠ¨
```bash
# ç”Ÿäº§ç¯å¢ƒå¯åŠ¨ï¼ˆå¤šè¿›ç¨‹ï¼‰
uvicorn app:app --host 0.0.0.0 --port 9999 --workers 4 --access-log

# ä½¿ç”¨systemdç®¡ç†ï¼ˆæ¨èï¼‰
sudo systemctl start clean-production-platform
sudo systemctl enable clean-production-platform
```

### æ•°æ®åº“åˆå§‹åŒ–
```bash
# è‡ªåŠ¨åˆå§‹åŒ–æ•°æ®åº“å’ŒåŸºç¡€æ•°æ®
python -c "from app.core.init_app import init_data; import asyncio; asyncio.run(init_data())"

# æ‰‹åŠ¨åˆ›å»ºè¶…çº§ç”¨æˆ·
python -c "
from app.controllers.user import user_controller, UserCreate
import asyncio

async def create_admin():
    await user_controller.create_user(
        UserCreate(
            username='admin',
            email='admin@admin.com',
            password='123456',
            is_active=True,
            is_superuser=True
        )
    )
    print('Admin user created successfully')

asyncio.run(create_admin())
"
```

## ğŸ“Š ç³»ç»Ÿç›‘æ§

### 1. æ—¥å¿—ç›‘æ§

#### æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f /var/log/clean-production-platform.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep "ERROR" /var/log/clean-production-platform.log | tail -20

# æŸ¥çœ‹è®¿é—®æ—¥å¿—
grep "POST\|GET\|PUT\|DELETE" /var/log/clean-production-platform.log | tail -50

# æŒ‰æ—¶é—´èŒƒå›´æŸ¥çœ‹æ—¥å¿—
grep "2025-01-20" /var/log/clean-production-platform.log
```

#### æ—¥å¿—åˆ†æè„šæœ¬
```bash
#!/bin/bash
# log_analysis.sh - æ—¥å¿—åˆ†æè„šæœ¬

LOG_FILE="/var/log/clean-production-platform.log"
DATE=$(date +%Y-%m-%d)

echo "=== æ¸…æ´ç”Ÿäº§å¹³å°æ—¥å¿—åˆ†ææŠ¥å‘Š - $DATE ==="
echo

# é”™è¯¯ç»Ÿè®¡
echo "1. é”™è¯¯ç»Ÿè®¡:"
grep "ERROR" $LOG_FILE | grep $DATE | wc -l
echo

# APIè°ƒç”¨ç»Ÿè®¡
echo "2. APIè°ƒç”¨ç»Ÿè®¡:"
echo "GETè¯·æ±‚: $(grep "GET" $LOG_FILE | grep $DATE | wc -l)"
echo "POSTè¯·æ±‚: $(grep "POST" $LOG_FILE | grep $DATE | wc -l)"
echo "PUTè¯·æ±‚: $(grep "PUT" $LOG_FILE | grep $DATE | wc -l)"
echo "DELETEè¯·æ±‚: $(grep "DELETE" $LOG_FILE | grep $DATE | wc -l)"
echo

# å“åº”æ—¶é—´åˆ†æ
echo "3. å“åº”æ—¶é—´åˆ†æ:"
grep "response_time" $LOG_FILE | grep $DATE | awk '{print $NF}' | sort -n | tail -10
echo

# ç”¨æˆ·æ´»è·ƒåº¦
echo "4. ç”¨æˆ·æ´»è·ƒåº¦:"
grep "user_id" $LOG_FILE | grep $DATE | awk '{print $NF}' | sort | uniq | wc -l
```

#### å®¡è®¡æ—¥å¿—æŸ¥è¯¢
```sql
-- æŸ¥è¯¢ç”¨æˆ·æ“ä½œæ—¥å¿—
SELECT 
    username,
    module,
    summary,
    method,
    path,
    status,
    response_time,
    created_at
FROM auditlog 
WHERE created_at >= datetime('now', '-1 day')
ORDER BY created_at DESC
LIMIT 100;

-- æŸ¥è¯¢APIè°ƒç”¨ç»Ÿè®¡
SELECT 
    method,
    path,
    COUNT(*) as call_count,
    AVG(response_time) as avg_response_time,
    MAX(response_time) as max_response_time
FROM auditlog 
WHERE created_at >= datetime('now', '-1 day')
GROUP BY method, path
ORDER BY call_count DESC;
```

### 2. ç³»ç»Ÿæ€§èƒ½ç›‘æ§

#### ç›‘æ§æŒ‡æ ‡è„šæœ¬
```bash
#!/bin/bash
# monitor.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

echo "=== æ¸…æ´ç”Ÿäº§å¹³å°ç³»ç»Ÿç›‘æ§ - $(date) ==="
echo

# 1. è¿›ç¨‹çŠ¶æ€
echo "1. è¿›ç¨‹çŠ¶æ€:"
ps aux | grep "uvicorn\|python.*run.py" | grep -v grep
echo

# 2. å†…å­˜ä½¿ç”¨
echo "2. å†…å­˜ä½¿ç”¨:"
free -h
echo

# 3. ç£ç›˜ä½¿ç”¨
echo "3. ç£ç›˜ä½¿ç”¨:"
df -h
echo

# 4. æ•°æ®åº“å¤§å°
echo "4. æ•°æ®åº“å¤§å°:"
if [ -f "db.sqlite3" ]; then
    ls -lh db.sqlite3
    echo "æ•°æ®åº“è®°å½•æ•°:"
    sqlite3 db.sqlite3 "SELECT COUNT(*) as total_records FROM (SELECT 'user' as table_name, COUNT(*) as count FROM user UNION ALL SELECT 'pcb_enterprise', COUNT(*) FROM pcb_enterprise UNION ALL SELECT 'auditlog', COUNT(*) FROM auditlog);"
fi
echo

# 5. ç½‘ç»œè¿æ¥
echo "5. ç½‘ç»œè¿æ¥:"
netstat -tlnp | grep :9999
echo

# 6. APIå¥åº·æ£€æŸ¥
echo "6. APIå¥åº·æ£€æŸ¥:"
curl -s -o /dev/null -w "HTTPçŠ¶æ€ç : %{http_code}, å“åº”æ—¶é—´: %{time_total}s\n" http://localhost:9999/api/v1/base/access_token
echo
```

#### æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```python
# performance_monitor.py - æ€§èƒ½ç›‘æ§è„šæœ¬
import asyncio
import sqlite3
import psutil
import time
from datetime import datetime

async def monitor_performance():
    """ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    
    # 1. ç³»ç»Ÿèµ„æºç›‘æ§
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    print(f"CPUä½¿ç”¨ç‡: {cpu_percent}%")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
    print(f"ç£ç›˜ä½¿ç”¨ç‡: {disk.percent}%")
    
    # 2. æ•°æ®åº“æ€§èƒ½ç›‘æ§
    conn = sqlite3.connect('db.sqlite3')
    cursor = conn.cursor()
    
    # æŸ¥è¯¢æ•°æ®åº“å¤§å°
    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
    table_count = cursor.fetchone()[0]
    
    # æŸ¥è¯¢è®°å½•æ€»æ•°
    cursor.execute("""
        SELECT COUNT(*) FROM (
            SELECT COUNT(*) FROM user
            UNION ALL
            SELECT COUNT(*) FROM pcb_enterprise
            UNION ALL
            SELECT COUNT(*) FROM auditlog
        )
    """)
    total_records = cursor.fetchone()[0]
    
    print(f"æ•°æ®åº“è¡¨æ•°é‡: {table_count}")
    print(f"æ€»è®°å½•æ•°: {total_records}")
    
    conn.close()
    
    # 3. APIå“åº”æ—¶é—´ç›‘æ§
    import requests
    try:
        start_time = time.time()
        response = requests.get('http://localhost:9999/api/v1/base/access_token', timeout=5)
        response_time = time.time() - start_time
        
        print(f"APIå“åº”æ—¶é—´: {response_time:.3f}s")
        print(f"APIçŠ¶æ€ç : {response.status_code}")
    except Exception as e:
        print(f"APIå¥åº·æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(monitor_performance())
```

### 3. å‘Šè­¦è®¾ç½®

#### ç³»ç»Ÿå‘Šè­¦è„šæœ¬
```bash
#!/bin/bash
# alert.sh - ç³»ç»Ÿå‘Šè­¦è„šæœ¬

# é…ç½®å‘Šè­¦é˜ˆå€¼
CPU_THRESHOLD=80
MEMORY_THRESHOLD=85
DISK_THRESHOLD=90
API_RESPONSE_THRESHOLD=5

# å‘Šè­¦å‡½æ•°
send_alert() {
    local message="$1"
    echo "$(date): ALERT - $message" >> /var/log/platform-alerts.log
    
    # å‘é€é‚®ä»¶å‘Šè­¦ï¼ˆéœ€è¦é…ç½®é‚®ä»¶æœåŠ¡ï¼‰
    # echo "$message" | mail -s "æ¸…æ´ç”Ÿäº§å¹³å°å‘Šè­¦" admin@company.com
    
    # å‘é€é’‰é’‰/ä¼ä¸šå¾®ä¿¡å‘Šè­¦ï¼ˆéœ€è¦é…ç½®webhookï¼‰
    # curl -X POST "https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN" \
    #      -H "Content-Type: application/json" \
    #      -d "{\"msgtype\":\"text\",\"text\":{\"content\":\"$message\"}}"
}

# æ£€æŸ¥CPUä½¿ç”¨ç‡
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')
if (( $(echo "$cpu_usage > $CPU_THRESHOLD" | bc -l) )); then
    send_alert "CPUä½¿ç”¨ç‡è¿‡é«˜: ${cpu_usage}%"
fi

# æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
memory_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100.0}')
if [ "$memory_usage" -gt "$MEMORY_THRESHOLD" ]; then
    send_alert "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${memory_usage}%"
fi

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
disk_usage=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
if [ "$disk_usage" -gt "$DISK_THRESHOLD" ]; then
    send_alert "ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${disk_usage}%"
fi

# æ£€æŸ¥APIå“åº”æ—¶é—´
api_response=$(curl -s -o /dev/null -w "%{time_total}" http://localhost:9999/api/v1/base/access_token)
if (( $(echo "$api_response > $API_RESPONSE_THRESHOLD" | bc -l) )); then
    send_alert "APIå“åº”æ—¶é—´è¿‡é•¿: ${api_response}s"
fi

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if ! pgrep -f "uvicorn.*app:app" > /dev/null; then
    send_alert "æœåŠ¡è¿›ç¨‹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€"
fi
```

#### å®šæ—¶ä»»åŠ¡é…ç½®
```bash
# æ·»åŠ åˆ°crontab
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹ä»»åŠ¡
# æ¯5åˆ†é’Ÿæ£€æŸ¥ç³»ç»ŸçŠ¶æ€
*/5 * * * * /path/to/monitor.sh >> /var/log/platform-monitor.log 2>&1

# æ¯10åˆ†é’Ÿæ£€æŸ¥å‘Šè­¦
*/10 * * * * /path/to/alert.sh

# æ¯å°æ—¶åˆ†ææ—¥å¿—
0 * * * * /path/to/log_analysis.sh >> /var/log/platform-analysis.log 2>&1

# æ¯å¤©å‡Œæ™¨2ç‚¹å¤‡ä»½æ•°æ®åº“
0 2 * * * /path/to/backup.sh >> /var/log/platform-backup.log 2>&1
```

## ğŸ’¾ æ•°æ®å¤‡ä»½ä¸æ¢å¤

### å¤‡ä»½ç­–ç•¥

#### æ•°æ®åº“å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# backup.sh - æ•°æ®åº“å¤‡ä»½è„šæœ¬

BACKUP_DIR="/var/backups/clean-production-platform"
DATE=$(date +%Y%m%d_%H%M%S)
DB_FILE="db.sqlite3"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# 1. å®Œæ•´å¤‡ä»½
echo "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
cp $DB_FILE $BACKUP_DIR/db_backup_$DATE.sqlite3

# 2. å‹ç¼©å¤‡ä»½
gzip $BACKUP_DIR/db_backup_$DATE.sqlite3

# 3. ä¿ç•™æœ€è¿‘30å¤©çš„å¤‡ä»½
find $BACKUP_DIR -name "db_backup_*.sqlite3.gz" -mtime +30 -delete

# 4. å¯¼å‡ºå…³é”®æ•°æ®ä¸ºSQL
sqlite3 $DB_FILE <<EOF
.output $BACKUP_DIR/data_export_$DATE.sql
.dump
EOF

echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR/db_backup_$DATE.sqlite3.gz"
echo "SQLå¯¼å‡ºå®Œæˆ: $BACKUP_DIR/data_export_$DATE.sql"

# 5. éªŒè¯å¤‡ä»½æ–‡ä»¶
if [ -f "$BACKUP_DIR/db_backup_$DATE.sqlite3.gz" ]; then
    echo "å¤‡ä»½æ–‡ä»¶éªŒè¯æˆåŠŸ"
else
    echo "å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥"
    exit 1
fi
```

#### å¢é‡å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# incremental_backup.sh - å¢é‡å¤‡ä»½è„šæœ¬

BACKUP_DIR="/var/backups/clean-production-platform/incremental"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# å¯¼å‡ºä»Šæ—¥æ–°å¢/ä¿®æ”¹çš„æ•°æ®
sqlite3 db.sqlite3 <<EOF
.output $BACKUP_DIR/incremental_$DATE.sql

-- å¯¼å‡ºä»Šæ—¥æ–°å¢çš„ç”¨æˆ·
SELECT * FROM user WHERE created_at >= date('now', '-1 day');

-- å¯¼å‡ºä»Šæ—¥æ–°å¢çš„ä¼ä¸š
SELECT * FROM pcb_enterprise WHERE created_at >= date('now', '-1 day');

-- å¯¼å‡ºä»Šæ—¥çš„å®¡è®¡æ—¥å¿—
SELECT * FROM auditlog WHERE created_at >= date('now', '-1 day');
EOF

echo "å¢é‡å¤‡ä»½å®Œæˆ: $BACKUP_DIR/incremental_$DATE.sql"
```

### æ¢å¤ç­–ç•¥

#### æ•°æ®åº“æ¢å¤è„šæœ¬
```bash
#!/bin/bash
# restore.sh - æ•°æ®åº“æ¢å¤è„šæœ¬

BACKUP_FILE="$1"
DB_FILE="db.sqlite3"

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <å¤‡ä»½æ–‡ä»¶è·¯å¾„>"
    echo "ç¤ºä¾‹: $0 /var/backups/clean-production-platform/db_backup_20250120_143000.sqlite3.gz"
    exit 1
fi

# æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$BACKUP_FILE" ]; then
    echo "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_FILE"
    exit 1
fi

echo "å¼€å§‹æ¢å¤æ•°æ®åº“..."

# 1. å¤‡ä»½å½“å‰æ•°æ®åº“
cp $DB_FILE ${DB_FILE}.backup.$(date +%Y%m%d_%H%M%S)

# 2. è§£å‹å¹¶æ¢å¤
if [[ $BACKUP_FILE == *.gz ]]; then
    gunzip -c $BACKUP_FILE > $DB_FILE
else
    cp $BACKUP_FILE $DB_FILE
fi

# 3. éªŒè¯æ¢å¤ç»“æœ
sqlite3 $DB_FILE "PRAGMA integrity_check;"

if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“æ¢å¤æˆåŠŸ"
else
    echo "æ•°æ®åº“æ¢å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¤‡ä»½æ–‡ä»¶"
    exit 1
fi
```

## ğŸ”„ ç‰ˆæœ¬å‡çº§ä¸å›æ»š

### å‡çº§æµç¨‹

#### ç‰ˆæœ¬å‡çº§è„šæœ¬
```bash
#!/bin/bash
# upgrade.sh - ç‰ˆæœ¬å‡çº§è„šæœ¬

NEW_VERSION="$1"
BACKUP_DIR="/var/backups/clean-production-platform"
DATE=$(date +%Y%m%d_%H%M%S)

if [ -z "$NEW_VERSION" ]; then
    echo "ç”¨æ³•: $0 <æ–°ç‰ˆæœ¬å·>"
    echo "ç¤ºä¾‹: $0 v1.2.0"
    exit 1
fi

echo "å¼€å§‹å‡çº§åˆ°ç‰ˆæœ¬: $NEW_VERSION"

# 1. åˆ›å»ºå‡çº§å‰å¤‡ä»½
echo "åˆ›å»ºå‡çº§å‰å¤‡ä»½..."
mkdir -p $BACKUP_DIR/upgrade_backups
cp db.sqlite3 $BACKUP_DIR/upgrade_backups/db_before_upgrade_$DATE.sqlite3
cp -r app $BACKUP_DIR/upgrade_backups/app_before_upgrade_$DATE

# 2. åœæ­¢æœåŠ¡
echo "åœæ­¢æœåŠ¡..."
systemctl stop clean-production-platform

# 3. å¤‡ä»½å½“å‰ä»£ç 
echo "å¤‡ä»½å½“å‰ä»£ç ..."
tar -czf $BACKUP_DIR/upgrade_backups/code_before_upgrade_$DATE.tar.gz app/ run.py requirements.txt

# 4. æ›´æ–°ä»£ç ï¼ˆå‡è®¾ä»Gitä»“åº“æ›´æ–°ï¼‰
echo "æ›´æ–°ä»£ç ..."
git fetch origin
git checkout $NEW_VERSION

# 5. æ›´æ–°ä¾èµ–
echo "æ›´æ–°ä¾èµ–..."
pip install -r requirements.txt

# 6. æ•°æ®åº“è¿ç§»
echo "æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
python -c "
from app.core.init_app import init_db
import asyncio
asyncio.run(init_db())
print('æ•°æ®åº“è¿ç§»å®Œæˆ')
"

# 7. å¯åŠ¨æœåŠ¡
echo "å¯åŠ¨æœåŠ¡..."
systemctl start clean-production-platform

# 8. å¥åº·æ£€æŸ¥
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if systemctl is-active --quiet clean-production-platform; then
    echo "æœåŠ¡å¯åŠ¨æˆåŠŸ"
    
    # APIå¥åº·æ£€æŸ¥
    if curl -f http://localhost:9999/api/v1/base/access_token > /dev/null 2>&1; then
        echo "APIå¥åº·æ£€æŸ¥é€šè¿‡"
        echo "å‡çº§å®Œæˆï¼"
    else
        echo "APIå¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå¼€å§‹å›æ»š..."
        ./rollback.sh $BACKUP_DIR/upgrade_backups/code_before_upgrade_$DATE.tar.gz
    fi
else
    echo "æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œå¼€å§‹å›æ»š..."
    ./rollback.sh $BACKUP_DIR/upgrade_backups/code_before_upgrade_$DATE.tar.gz
fi
```

### å›æ»šç­–ç•¥

#### å›æ»šè„šæœ¬
```bash
#!/bin/bash
# rollback.sh - å›æ»šè„šæœ¬

BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <å¤‡ä»½æ–‡ä»¶è·¯å¾„>"
    echo "ç¤ºä¾‹: $0 /var/backups/clean-production-platform/upgrade_backups/code_before_upgrade_20250120_143000.tar.gz"
    exit 1
fi

echo "å¼€å§‹å›æ»šæ“ä½œ..."

# 1. åœæ­¢æœåŠ¡
echo "åœæ­¢æœåŠ¡..."
systemctl stop clean-production-platform

# 2. æ¢å¤ä»£ç 
echo "æ¢å¤ä»£ç ..."
tar -xzf $BACKUP_FILE -C /

# 3. æ¢å¤æ•°æ®åº“ï¼ˆå¦‚æœæœ‰å¯¹åº”çš„æ•°æ®åº“å¤‡ä»½ï¼‰
BACKUP_DIR=$(dirname $BACKUP_FILE)
DB_BACKUP=$(find $BACKUP_DIR -name "db_before_upgrade_*.sqlite3" | head -1)

if [ -n "$DB_BACKUP" ]; then
    echo "æ¢å¤æ•°æ®åº“..."
    cp $DB_BACKUP db.sqlite3
fi

# 4. é‡æ–°å®‰è£…ä¾èµ–
echo "é‡æ–°å®‰è£…ä¾èµ–..."
pip install -r requirements.txt

# 5. å¯åŠ¨æœåŠ¡
echo "å¯åŠ¨æœåŠ¡..."
systemctl start clean-production-platform

# 6. å¥åº·æ£€æŸ¥
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

if systemctl is-active --quiet clean-production-platform; then
    echo "å›æ»šå®Œæˆï¼ŒæœåŠ¡å·²å¯åŠ¨"
else
    echo "å›æ»šå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥"
    exit 1
fi
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜è¯Šæ–­

#### æœåŠ¡å¯åŠ¨å¤±è´¥
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep :9999

# æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
ps aux | grep uvicorn

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
journalctl -u clean-production-platform -f

# æ£€æŸ¥Pythonç¯å¢ƒ
python --version
pip list | grep fastapi
```

#### æ•°æ®åº“è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
ls -la db.sqlite3

# æ£€æŸ¥æ•°æ®åº“æƒé™
sqlite3 db.sqlite3 "PRAGMA integrity_check;"

# æ£€æŸ¥æ•°æ®åº“è¡¨
sqlite3 db.sqlite3 ".tables"

# æ£€æŸ¥æ•°æ®åº“å¤§å°
du -h db.sqlite3
```

#### APIå“åº”å¼‚å¸¸
```bash
# æ£€æŸ¥APIçŠ¶æ€
curl -v http://localhost:9999/api/v1/base/access_token

# æ£€æŸ¥é”™è¯¯æ—¥å¿—
grep "ERROR" /var/log/clean-production-platform.log | tail -20

# æ£€æŸ¥è¯·æ±‚æ—¥å¿—
grep "POST\|GET" /var/log/clean-production-platform.log | tail -20
```

### æ€§èƒ½é—®é¢˜è¯Šæ–­

#### æ…¢æŸ¥è¯¢åˆ†æ
```sql
-- æŸ¥æ‰¾æ…¢æŸ¥è¯¢ï¼ˆéœ€è¦å¯ç”¨SQLiteçš„æŸ¥è¯¢æ—¥å¿—ï¼‰
-- åˆ†ææ•°æ®åº“æ€§èƒ½
EXPLAIN QUERY PLAN SELECT * FROM pcb_enterprise WHERE audit_status = 'completed';

-- æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
.schema pcb_enterprise

-- åˆ†æè¡¨å¤§å°
SELECT 
    name,
    COUNT(*) as row_count
FROM sqlite_master 
WHERE type='table' 
ORDER BY row_count DESC;
```

#### å†…å­˜æ³„æ¼æ£€æŸ¥
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨è¶‹åŠ¿
ps aux --sort=-%mem | head -10

# æ£€æŸ¥Pythonè¿›ç¨‹å†…å­˜
ps -o pid,ppid,cmd,%mem,%cpu --sort=-%mem | grep python

# ç›‘æ§å†…å­˜ä½¿ç”¨
watch -n 5 'ps aux | grep python | grep -v grep'
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–

#### ç´¢å¼•ä¼˜åŒ–
```sql
-- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_pcb_enterprise_audit_status ON pcb_enterprise(audit_status);
CREATE INDEX IF NOT EXISTS idx_pcb_enterprise_region ON pcb_enterprise(region);
CREATE INDEX IF NOT EXISTS idx_auditlog_user_id ON auditlog(user_id);
CREATE INDEX IF NOT EXISTS idx_auditlog_created_at ON auditlog(created_at);

-- å¤åˆç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_pcb_enterprise_status_region ON pcb_enterprise(audit_status, region);
```

#### æŸ¥è¯¢ä¼˜åŒ–
```python
# ä¼˜åŒ–å‰ï¼šå…¨è¡¨æ‰«æ
enterprises = await PCBEnterprise.all()

# ä¼˜åŒ–åï¼šä½¿ç”¨ç´¢å¼•å’Œåˆ†é¡µ
enterprises = await PCBEnterprise.filter(
    audit_status='completed'
).offset(0).limit(20).all()

# ä¼˜åŒ–å‰ï¼šN+1æŸ¥è¯¢
for enterprise in enterprises:
    results = await PCBAuditResult.filter(enterprise_id=enterprise.id).all()

# ä¼˜åŒ–åï¼šæ‰¹é‡æŸ¥è¯¢
enterprise_ids = [e.id for e in enterprises]
results = await PCBAuditResult.filter(enterprise_id__in=enterprise_ids).all()
```

### åº”ç”¨ä¼˜åŒ–

#### ç¼“å­˜ç­–ç•¥
```python
# ä½¿ç”¨å†…å­˜ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=128)
def get_indicator_schemes(indicator_id: int):
    """ç¼“å­˜æŒ‡æ ‡æ–¹æ¡ˆæ•°æ®"""
    # æŸ¥è¯¢é€»è¾‘
    pass

# ä½¿ç”¨Redisç¼“å­˜ï¼ˆéœ€è¦å®‰è£…redisï¼‰
import redis
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_api_response(key: str, data: dict, expire: int = 3600):
    """ç¼“å­˜APIå“åº”"""
    redis_client.setex(key, expire, json.dumps(data))
```

#### å¼‚æ­¥ä¼˜åŒ–
```python
# å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚
import asyncio

async def batch_process_enterprises(enterprise_ids: list):
    """æ‰¹é‡å¤„ç†ä¼ä¸šæ•°æ®"""
    tasks = []
    for enterprise_id in enterprise_ids:
        task = process_enterprise(enterprise_id)
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results
```

## ğŸ”’ å®‰å…¨è¿ç»´

### å®‰å…¨åŠ å›º

#### ç³»ç»Ÿå®‰å…¨é…ç½®
```bash
# 1. é˜²ç«å¢™é…ç½®
ufw enable
ufw allow 22/tcp    # SSH
ufw allow 9999/tcp # åº”ç”¨ç«¯å£
ufw deny 3306/tcp  # æ•°æ®åº“ç«¯å£ï¼ˆå¦‚æœä½¿ç”¨MySQLï¼‰

# 2. æ–‡ä»¶æƒé™è®¾ç½®
chmod 600 db.sqlite3
chmod 644 run.py
chmod 755 app/

# 3. ç”¨æˆ·æƒé™ç®¡ç†
# åˆ›å»ºä¸“ç”¨ç”¨æˆ·è¿è¡Œåº”ç”¨
useradd -r -s /bin/false cleanprod
chown -R cleanprod:cleanprod /opt/clean-production-platform
```

#### åº”ç”¨å®‰å…¨é…ç½®
```python
# å®‰å…¨ä¸­é—´ä»¶é…ç½®
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.httpsredirect import HTTPSRedirectMiddleware

app.add_middleware(TrustedHostMiddleware, allowed_hosts=["yourdomain.com"])
app.add_middleware(HTTPSRedirectMiddleware)

# å®‰å…¨å¤´é…ç½®
from fastapi.middleware.trustedhost import TrustedHostMiddleware

@app.middleware("http")
async def add_security_headers(request: Request, call_next):
    response = await call_next(request)
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-XSS-Protection"] = "1; mode=block"
    return response
```

### å®‰å…¨ç›‘æ§

#### å®‰å…¨æ—¥å¿—ç›‘æ§
```bash
#!/bin/bash
# security_monitor.sh - å®‰å…¨ç›‘æ§è„šæœ¬

LOG_FILE="/var/log/clean-production-platform.log"

# ç›‘æ§å¼‚å¸¸ç™»å½•
echo "=== å¼‚å¸¸ç™»å½•ç›‘æ§ ==="
grep "authentication failed\|invalid token" $LOG_FILE | tail -10

# ç›‘æ§æƒé™å¼‚å¸¸
echo "=== æƒé™å¼‚å¸¸ç›‘æ§ ==="
grep "permission denied\|forbidden" $LOG_FILE | tail -10

# ç›‘æ§SQLæ³¨å…¥å°è¯•
echo "=== SQLæ³¨å…¥ç›‘æ§ ==="
grep -i "union\|select\|insert\|delete\|drop" $LOG_FILE | tail -10

# ç›‘æ§å¼‚å¸¸è¯·æ±‚
echo "=== å¼‚å¸¸è¯·æ±‚ç›‘æ§ ==="
grep "status_code.*[45][0-9][0-9]" $LOG_FILE | tail -10
```

## ğŸ“‹ è¿ç»´æ£€æŸ¥æ¸…å•

### æ—¥å¸¸æ£€æŸ¥æ¸…å•
- [ ] æœåŠ¡çŠ¶æ€æ£€æŸ¥
- [ ] ç³»ç»Ÿèµ„æºç›‘æ§
- [ ] æ—¥å¿—æ–‡ä»¶å¤§å°æ£€æŸ¥
- [ ] æ•°æ®åº“å¤‡ä»½éªŒè¯
- [ ] APIå¥åº·æ£€æŸ¥
- [ ] å®‰å…¨æ—¥å¿—å®¡æŸ¥

### å‘¨åº¦æ£€æŸ¥æ¸…å•
- [ ] æ€§èƒ½æŒ‡æ ‡åˆ†æ
- [ ] é”™è¯¯æ—¥å¿—ç»Ÿè®¡
- [ ] ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ
- [ ] æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–
- [ ] å®‰å…¨æ¼æ´æ‰«æ
- [ ] å¤‡ä»½ç­–ç•¥è¯„ä¼°

### æœˆåº¦æ£€æŸ¥æ¸…å•
- [ ] ç³»ç»Ÿç‰ˆæœ¬æ›´æ–°
- [ ] ä¾èµ–åŒ…å®‰å…¨æ›´æ–°
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç¾éš¾æ¢å¤æ¼”ç»ƒ
- [ ] å®¹é‡è§„åˆ’è¯„ä¼°
- [ ] è¿ç»´æ–‡æ¡£æ›´æ–°

## ğŸ“ åº”æ€¥å“åº”

### ç´§æ€¥è”ç³»ä¿¡æ¯
- **æŠ€æœ¯è´Ÿè´£äºº**: [è”ç³»æ–¹å¼]
- **ç³»ç»Ÿç®¡ç†å‘˜**: [è”ç³»æ–¹å¼]
- **æ•°æ®åº“ç®¡ç†å‘˜**: [è”ç³»æ–¹å¼]

### åº”æ€¥å¤„ç†æµç¨‹
1. **é—®é¢˜å‘ç°**: ç›‘æ§å‘Šè­¦æˆ–ç”¨æˆ·åé¦ˆ
2. **é—®é¢˜ç¡®è®¤**: éªŒè¯é—®é¢˜å½±å“èŒƒå›´
3. **åº”æ€¥å¤„ç†**: å®æ–½ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
4. **æ ¹å› åˆ†æ**: æ·±å…¥åˆ†æé—®é¢˜åŸå› 
5. **æ°¸ä¹…ä¿®å¤**: å®æ–½æ°¸ä¹…è§£å†³æ–¹æ¡ˆ
6. **ç»éªŒæ€»ç»“**: æ›´æ–°è¿ç»´æ–‡æ¡£

### å¸¸è§åº”æ€¥åœºæ™¯
- **æœåŠ¡å®•æœº**: é‡å¯æœåŠ¡ â†’ æ£€æŸ¥æ—¥å¿— â†’ åˆ†æåŸå› 
- **æ•°æ®åº“æŸå**: æ¢å¤å¤‡ä»½ â†’ éªŒè¯æ•°æ® â†’ ä¿®å¤é—®é¢˜
- **æ€§èƒ½å¼‚å¸¸**: æ‰©å®¹èµ„æº â†’ ä¼˜åŒ–ä»£ç  â†’ ç›‘æ§æ•ˆæœ
- **å®‰å…¨äº‹ä»¶**: éš”ç¦»ç³»ç»Ÿ â†’ åˆ†ææ”»å‡» â†’ ä¿®å¤æ¼æ´

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**ç»´æŠ¤å›¢é˜Ÿ**: æ¸…æ´ç”Ÿäº§æ™ºæ…§å®¡æ ¸å¹³å°è¿ç»´ç»„  
**æŠ€æœ¯æ”¯æŒ**: FastAPI + Tortoise ORM + SQLite
